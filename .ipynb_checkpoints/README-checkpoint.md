# Comparison of Federated Learning Algorithms with Nelder-Mead Hyperparameter Optimization

This is an adaption of [Federated Learning Based on Dynamic Regularization](https://openreview.net/pdf?id=B7v4QMR6Z9w). Original codebase was created by the authors of the work, but modified for hyperparameter tuning with Nelder-Mead.

### Requirements

Please install the required packages. The code is compiled with Python 3.7 dependencies in a virtual environment via

```pip install -r requirements.txt```

### Instructions

Example code to run FedDyn and FedProx are commented out, but could be utilized after ensuring that lr_decay_per_round is properly set to 1 when not decay, and the proper rate when wanting t test decay. For a certain set of hyperparameters, code will run both a baseline non-tuned run of federated learning, denoted with hpo_method = 'hpona' for constant learning rate or hpo_method = 'decay' for a constant decay per round. The decay is implemented after 

Example codes to run FedDyn as well as baseline methods (FedAvg, FedProx and SCAFFOLD) with the synthetic dataset and CIFAR10 is given in ```example_code_synthetic.py``` and ```example_code_emnist.py```.

### Hyperparameter Optimization Instructions

hpo_method controls the method of hyperparameter optimization. 'hpona' means HPO not applied, and will maintain constant step size. 'decay' will induce a per-round learning rate decay equal to the fraction set. 'nm' will induce Nelder-Mead with parameters hpo_epoch, hpo_maxiter, and hpo_per. hpo_method_2 is the method of comparison. Typically, this should be set to 'decay' for non-synthetic datasets and set to 'hpona' for the synthetic dataset, which are the baseline methods from the FedDyn paper. You can also rename it to be the suffix of a saved file name such that you can compare multiple methods. For example, a file named 'Scaffold_nm_123' with saved data can be loaded into a model using 'nm_123' as the hpo_method or hpo_method_2. This allows for easy comparison of methods, especially those with different hyperparameters of Nelder-Mead.

The parameters for Nelder-Mead are explained thoroughly in the paper. hpo_epoch refers to the number of local epochs of SGD with trial learning rate for an iteration of Nelder-Mead. hpo_maxiter refers to the max number of Nelder-Mead iterations. hpo_per refers to how often the Nelder-Mead algorithm is run, with hpo_per meaning that it is run once every (hpo_per) communication rounds.

#### Generate IID and Dirichlet distributions on various datasets:<br/>
CIFAR-10 IID, 100 partitions, balanced data
```
data_obj = DatasetObject(dataset='CIFAR10', n_client=100, rule='iid', unbalanced_sgm=0)
```
CIFAR-10 Dirichlet (0.6), 100 partitions, balanced data
```
data_obj = DatasetObject(dataset='CIFAR10', n_client=100, unbalanced_sgm=0, rule='Dirichlet', rule_arg=0.6)
```
EMNIST Dirichlet (0.3), 100 partitions, balanced data
```
data_obj = DatasetObject(dataset='emnist', n_client=100, unbalanced_sgm=0, rule='Dirichlet', rule_arg=0.3)

```
EMNIST needs to be downloaded from this [link](https://www.nist.gov/itl/products-and-services/emnist-dataset).<br/>
Shakespeare is generated by using [LEAF](https://github.com/TalwalkarLab/leaf). 

The example codes construct the federated datasets, train methods and plot loss curve.

### Citation

```
@inproceedings{
acar2021federated,
title={Federated Learning Based on Dynamic Regularization},
author={Durmus Alp Emre Acar and Yue Zhao and Ramon Matas and Matthew Mattina and Paul Whatmough and Venkatesh Saligrama},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=B7v4QMR6Z9w}
}
```